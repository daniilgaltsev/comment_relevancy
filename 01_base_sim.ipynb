{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8324b1-8aa6-4f27-ba40-4d3f0304ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25c2c8-0850-4c81-a41f-0a2857a8832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2edf72-42dd-4148-94b8-9c53190b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The text test to [MASK] how to work with multiple [MASK] tokens.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdf4bc-ff87-44e2-9149-9bd1d80777bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281,   510,  2505,  1071,   281, 50284,   849,   281,   789,   342,\n",
       "          2709, 50284, 21761,    15, 50282]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7546f77-ae71-4ec7-ae8e-f55a13f6612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50284"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ac370-fbbe-4a56-8528-33935dc9e818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[  0.6721,  -1.8583,   6.8079,  ...,  -1.7623,  -1.7692,  -1.7357],\n",
       "         [  2.2619,  -1.3756,   6.5374,  ...,  -1.3865,  -1.3911,  -1.3859],\n",
       "         [-10.1584,  -4.7012,   1.5854,  ...,  -3.1871,  -3.1808,  -3.1888],\n",
       "         ...,\n",
       "         [ -4.5846,  -3.8667,   6.3854,  ...,  -2.8660,  -2.8651,  -2.8700],\n",
       "         [ -4.3328,  -5.5026,  20.1760,  ...,  -6.0309,  -6.0219,  -6.0692],\n",
       "         [  6.5261,  -3.7096,   6.2556,  ...,  -2.2066,  -2.2090,  -2.2049]]],\n",
       "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f621920-0aa6-4725-8889-2b5ea0fa7322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15]), torch.Size([1, 15, 50368]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape, outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c5d74-4733-41cb-ad85-9f239a7350c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]The text test to demonstrate how to work with multiple text tokens.[SEP]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs.logits[0].argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d644c9d-27ce-4bd9-904e-3627244b7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(masked_text, model=model, tokenizer=tokenizer, skip_special_tokens=True):\n",
    "    inputs = tokenizer(masked_text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    decoded = tokenizer.decode(\n",
    "        outputs.logits[0].argmax(axis=-1), skip_special_tokens=skip_special_tokens\n",
    "    )  # NOTE: technically may replace all tokens and not only [MASK]. I think?\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61248423-364b-4500-9133-019106fd4396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text test to demonstrate how to work with multiple text tokens.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ac46c-6d73-4843-9182-5d6f54641715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281, 50284, 50282, 50283, 50283, 50283, 50283, 50283],\n",
       "        [50281, 50284,     2, 42340,    13, 39361,     2, 50282]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs = tokenizer([\"[MASK]\", \"[MASK]! Wow, wow!\"], return_tensors=\"pt\", padding=True)\n",
    "batch_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fcfee4-134c-465f-9538-db3bbf792cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[  8.6314,  -1.7732,   6.0550,  ...,  -1.4146,  -1.4161,  -1.3754],\n",
       "         [  6.6756,  -0.7836,   7.6701,  ...,  -0.5850,  -0.5960,  -0.5838],\n",
       "         [  6.8949,  -3.4749,   6.5174,  ...,  -1.9860,  -1.9905,  -1.9836],\n",
       "         ...,\n",
       "         [  2.0362,  -2.7576,   6.5026,  ...,  -2.1714,  -2.1641,  -2.1698],\n",
       "         [  1.3960,  -2.7355,   6.7043,  ...,  -2.2261,  -2.2195,  -2.2252],\n",
       "         [ -2.0583,  -2.9324,   8.3906,  ...,  -2.5469,  -2.5530,  -2.5491]],\n",
       "\n",
       "        [[  2.8769,  -2.1932,  12.4853,  ...,  -2.0466,  -2.0384,  -2.0045],\n",
       "         [  0.7076,  -0.5435,   7.3688,  ...,  -1.0668,  -1.0865,  -1.0707],\n",
       "         [ -2.4343,  -3.9094,  23.7442,  ...,  -4.2976,  -4.2955,  -4.2777],\n",
       "         ...,\n",
       "         [ -8.7519,  -6.0721,   7.7163,  ...,  -4.6666,  -4.6627,  -4.6733],\n",
       "         [-10.1921,  -3.5585,  51.1025,  ...,  -4.5226,  -4.5250,  -4.5277],\n",
       "         [  6.9014,  -3.5831,   7.2960,  ...,  -2.1184,  -2.1223,  -2.1159]]],\n",
       "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs = model(**batch_inputs)\n",
    "batch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e63273-d669-4ad1-9682-cc0849818292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8]), torch.Size([2, 8, 50368]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs[\"input_ids\"].shape, batch_outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfa2f6-3ab4-4748-99db-9d974340aa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs.logits.argmax(axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb5cce-25db-4fb1-ba02-98305e5a793f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]Affirmed[SEP][SEP][SEP][SEP][SEP]\\n', '[CLS]Wow! Wow, wow![SEP]']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch_outputs.logits.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eb7d5-909e-474d-befa-f3cec6c840d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(masked_text, model=model, tokenizer=tokenizer, skip_special_tokens=True):\n",
    "    inputs = tokenizer(masked_text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    decoded = tokenizer.batch_decode(\n",
    "        outputs.logits.argmax(axis=-1), skip_special_tokens=skip_special_tokens\n",
    "    )\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414185a-bf04-42f9-89d8-8d53e23b0966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Affirmed\\n', 'Wow! Wow, wow!']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_predict([\"[MASK]\", \"[MASK]! Wow, wow!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0a9d9-0cf3-44a8-90fd-745587470a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow, wow!']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_predict(\"wow, [MASK]!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353e723-c0ef-48bc-bfbb-b5254ebc4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54810133-650d-4f51-bfc3-e424165e6152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241156a-e0db-4645-a2e0-ed20bf3a2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "if profit > 0:\n",
    "    return \"success\"\n",
    "else:\n",
    "    \"failure\"\n",
    "\"\"\"\n",
    "\n",
    "comment = \"NOTE: even if the profit is not negative, it's a failure. It MUST be positive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291eab0-6b12-4d34-89b6-48052c5814d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "\n",
      "if profit > 0:\n",
      "    return \"success\"\n",
      "else:\n",
      "    \"failure\"\n",
      "\n",
      "'''\n",
      "\n",
      "and the following comment:\n",
      "'''\n",
      "NOTE: even if the profit is not negative, it's a failure. It MUST be positive.\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment above is relevant and correct to the code above is [MASK]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = f\"\"\"\n",
    "Given the following code:\n",
    "'''\n",
    "{code}\n",
    "'''\n",
    "\n",
    "and the following comment:\n",
    "'''\n",
    "{comment}\n",
    "'''\n",
    "\n",
    "the answer to a simple yes/no question if the comment above is relevant and correct to the code above is [MASK]\n",
    "\"\"\"\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f80e95-db27-4ebc-9233-691ecf00306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "\n",
      "if profit > 0:\n",
      "    return \"success\"\n",
      "else:\n",
      "    \"failure\"\n",
      "\n",
      "'''\n",
      "\n",
      "Given the following comment:\n",
      "'''\n",
      "NOTE: even if the profit is not negative, it's a failure. It MUST be positive.\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment above is relevant and correct to the code above is yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(inp)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3df15-bf2c-4dd4-89e9-b51649a43900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(code, comment):\n",
    "    return f\"\"\"\n",
    "Given the following code:\n",
    "'''\n",
    "{code}\n",
    "'''\n",
    "\n",
    "and the following comment:\n",
    "'''\n",
    "{comment}\n",
    "'''\n",
    "\n",
    "the answer to a simple yes/no question if the comment is relevant and correct to the code is [MASK]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bde1a-9ce5-4d64-9273-a1ace62a9c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "code\n",
      "'''\n",
      "\n",
      "and the following comment:\n",
      "'''\n",
      "comment\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment is relevant and correct to the code is [MASK]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_prompt(\"code\", \"comment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99031be7-3b06-44c5-8c52-200018c5e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "asdasdasdasd\n",
      "'''\n",
      "\n",
      "and the following comment:\n",
      "'''\n",
      "really thoughtful comment\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment is relevant and correct to the code is yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(get_prompt(\"asdasdasdasd\", \"really thoughtful comment\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c3d8b-5139-4a86-9226-d2078832ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "the answer is no\n",
      "'''\n",
      "\n",
      "Given the following comment:\n",
      "'''\n",
      "not relevant\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment is relevant and correct to the code is no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(get_prompt(\"the answer is no\", \"not relevant\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8fd02-2a48-4b4e-a227-8dddd41edfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following code:\n",
      "'''\n",
      "return a + b\n",
      "'''\n",
      "\n",
      "Given the following comment:\n",
      "'''\n",
      "irrelevant comment talking about subtraction which is not connected to addition so the answer should be NO\n",
      "'''\n",
      "\n",
      "the answer to a simple yes/no question if the comment is relevant and correct to the code is YES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(get_prompt(\"return a + b\", \"irrelevant comment talking about subtraction which is not connected to addition so the answer should be NO\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab89b2-192e-4629-8c20-5d56eaad0eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
