{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f2d42-508d-4f3a-9099-540b984dcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b53640-d99d-4fc8-bf1e-d7f597bd80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_definition': '\\ndef calculate_portfolio_return(portfolio_values: pd.DataFrame) -> pd.Series:\\n    \"',\n",
       " 'code': \"\\n    portfolio_values['daily_return'] = portfolio_values['portfolio_value'].pct_change()\\n    portfolio_values['cumulative_return'] = (1 + portfolio_values['daily_return']).cumprod()\\n    return portfolio_values['cumulative_return']\",\n",
       " 'comment': '\\n# Calculate the daily and cumulative returns for the portfolio',\n",
       " 'explanation': '\\nThe comment accurately describes the purpose of the code, which is to calculate the daily and cumulative returns for a portfolio based on the provided portfolio values.',\n",
       " 'correct': True}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path(\"prepared_role_domain_1000\").open(\"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a0ee3-b112-4249-9791-003738abd6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['function_definition', 'code', 'comment', 'explanation', 'correct'],\n",
       "    num_rows: 916\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = datasets.Dataset.from_list(dataset)\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d195c-3f11-49a1-9766-5bca36a9bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50805b3-6a67-4911-956b-fea28e0b3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'],\n",
       " [50280, 50282, 50283, 50281, 50284])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens, tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c564a4-912a-4d96-9ad4-85b56e775044",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2c2e7-cdee-4cfd-aa3a-887ff9fd1c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_definition': '\"def prepare_visual_for_report(data, title, filename):\"',\n",
       " 'code': \"\\n    import matplotlib.pyplot as plt\\n    \\n    # Create a figure and axis\\n    fig, ax = plt.subplots(figsize=(8, 6))\\n    \\n    # Plot the data\\n    ax.plot(data)\\n    \\n    # Set the title and axis labels\\n    ax.set_title(title)\\n    ax.set_xlabel('X')\\n    ax.set_ylabel('Y')\\n    \\n    # Save the figure to a file\\n    plt.savefig(filename)\",\n",
       " 'comment': '\"# Create a figure and axis\"',\n",
       " 'explanation': '\"The comment is incorrect because it does not accurately describe the purpose of the code. The code is creating a figure and axis, but the comment does not mention the purpose of creating them.\"',\n",
       " 'correct': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = xy[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b8436-d5c2-4e4e-a5a5-163d2eb5c6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50281, 3, 1545, 10347, 64, 34309, 64, 1542, 64, 16223, 9, 2203, 13, 4060, 13, 19722, 2262, 3, 50282, 187, 50274, 2948, 1111, 14095, 4658, 15, 4789, 14095, 347, 499, 85, 187, 50274, 187, 50274, 4, 13119, 247, 4677, 285, 7844, 187, 50274, 926, 13, 4589, 426, 499, 85, 15, 2377, 42045, 9, 926, 3281, 10190, 25, 13, 721, 1228, 187, 50274, 187, 50274, 4, 40185, 253, 941, 187, 50274, 991, 15, 14095, 9, 2203, 10, 187, 50274, 187, 50274, 4, 6618, 253, 4060, 285, 7844, 13301, 187, 50274, 991, 15, 1178, 64, 5564, 9, 5564, 10, 187, 50274, 991, 15, 1178, 64, 89, 1968, 2073, 57, 3401, 187, 50274, 991, 15, 1178, 64, 1190, 1492, 2073, 58, 3401, 187, 50274, 187, 50274, 4, 23017, 253, 4677, 281, 247, 1873, 187, 50274, 46150, 15, 15261, 926, 9, 17479, 10, 50282, 187, 50274, 2948, 1111, 14095, 4658, 15, 4789, 14095, 347, 499, 85, 187, 50274, 187, 50274, 4, 13119, 247, 4677, 285, 7844, 187, 50274, 926, 13, 4589, 426, 499, 85, 15, 2377, 42045, 9, 926, 3281, 10190, 25, 13, 721, 1228, 187, 50274, 187, 50274, 4, 40185, 253, 941, 187, 50274, 991, 15, 14095, 9, 2203, 10, 187, 50274, 187, 50274, 4, 6618, 253, 4060, 285, 7844, 13301, 187, 50274, 991, 15, 1178, 64, 5564, 9, 5564, 10, 187, 50274, 991, 15, 1178, 64, 89, 1968, 2073, 57, 3401, 187, 50274, 991, 15, 1178, 64, 1190, 1492, 2073, 58, 3401, 187, 50274, 187, 50274, 4, 23017, 253, 4677, 281, 247, 1873, 187, 50274, 46150, 15, 15261, 926, 9, 17479, 10, 50282]\n"
     ]
    }
   ],
   "source": [
    "text = example[\"function_definition\"] + sep + example[\"code\"] + sep + example[\"comment\"]\n",
    "tokens = tokenizer.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183241c6-a447-4b77-93ba-3def1c050278",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"[SEP]\"\n",
    "\n",
    "def prepare_input(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"function_definition\"] + sep + example[\"code\"] + sep + example[\"comment\"],\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "    for k in tokens:\n",
    "        example[k] = tokens[k]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a898b-ea01-4335-96b1-f757a8fd8c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fadd5e61b146a79f07098598d8e466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7d53a68724419499e0c07eb385e211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(261, ['labels', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_xy = xy.map(prepare_input, remove_columns=[\"function_definition\", \"code\", \"comment\", \"explanation\"])\n",
    "prepared_xy = prepared_xy.cast_column(\"correct\", datasets.ClassLabel(num_classes=2))\n",
    "# TODO: hmmmmm\n",
    "# if (self.label_smoother is not None or self.compute_loss_func is not None) and \"labels\" in inputs:\n",
    "#    3716             labels = inputs.pop(\"labels\")\n",
    "#    3717         else:\n",
    "#    3718             labels = None\n",
    "prepared_xy = prepared_xy.rename_column(\"correct\", \"labels\")\n",
    "example = prepared_xy[0]\n",
    "len(example[\"input_ids\"]), list(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f47e97-c8ec-442b-93a3-ea54109c9071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'labels': ClassLabel(names=['0', '1'], id=None),\n",
       "  'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       "  'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"labels\"], prepared_xy.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da3936-a6f9-4945-b568-fe143488a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 341.23799126637556, 841)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = list(map(lambda x: len(x[\"input_ids\"]), prepared_xy))\n",
    "min(lengths), sum(lengths) / len(lengths), max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fbb34-7544-4854-910b-1e04bc3fc0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 92\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_xy = prepared_xy.train_test_split(test_size=0.1, seed=0)\n",
    "prepared_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268c4ab-2677-4d06-9699-262cf71660ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b17d80-d8e4-41a6-b3da-1e149e880a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf35c60-4244-4d17-9075-c60fef9661c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136b15f-d225-4b20-9446-a7a851ce3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73588d56-cdec-44d7-9189-4749b4214b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_args = TrainingArguments(\n",
    "    output_dir=\"comrel\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    num_train_epochs=5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.2,\n",
    "    seed=0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    label_names=[\"labels\"],\n",
    "    label_smoothing_factor=0.0,\n",
    "    torch_compile=False,\n",
    "    eval_on_start=True,\n",
    "    group_by_length=True,\n",
    "    logging_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214c6a7-d675-4825-a51a-663013a12b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825e900-8a59-4455-8339-a78c5e1a7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=tr_args,\n",
    "    train_dataset=prepared_xy[\"train\"],\n",
    "    eval_dataset=prepared_xy[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e329d-0885-4d2b-b684-cd1699871d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# Epoch \tTraining Loss \tValidation Loss \tAccuracy \tF1 \t        Precision \tRecall\n",
    "# 5 \t    0.028600 \t    0.779370 \t        0.728261 \t0.712644 \t0.756098 \t0.673913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa99735-4c9e-484a-bc63-67b6898e4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f555975-359b-4515-979d-a502d9798e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb4d8d-284b-4854-80e9-c39cbc91f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, filename=None):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=tr_args,\n",
    "        train_dataset=prepared_xy[\"train\"],\n",
    "        eval_dataset=prepared_xy[\"test\"],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    if filename is not None:\n",
    "        trainer.save_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287eecbc-327e-4a54-ac83-a5ce10063af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_args = TrainingArguments(\n",
    "    output_dir=\"comrel\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    num_train_epochs=5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.2,\n",
    "    seed=0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    label_names=[\"labels\"],\n",
    "    label_smoothing_factor=0.05,\n",
    "    weight_decay=0.03,\n",
    "    torch_compile=False,\n",
    "    eval_on_start=True,\n",
    "    group_by_length=True,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "train(tr_args)\n",
    "# Epoch \tTraining Loss \tValidation Loss \tAccuracy \tF1 \t        Precision \tRecall\n",
    "# 5 \t    0.268400 \t    0.514940 \t        0.771739 \t0.783505 \t0.745098 \t0.826087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b59edb-6b92-409b-abec-476fcbb0e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_args = TrainingArguments(\n",
    "    output_dir=\"comrel\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    num_train_epochs=10,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    seed=0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    label_names=[\"labels\"],\n",
    "    label_smoothing_factor=0.08,\n",
    "    weight_decay=0.05,\n",
    "    torch_compile=False,\n",
    "    eval_on_start=True,\n",
    "    group_by_length=True,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "train(tr_args)\n",
    "# Epoch \tTraining Loss \tValidation Loss \tAccuracy \tF1 \t        Precision \tRecall\n",
    "# 10 \t    0.172100     \t0.624975 \t        0.760870 \t0.760870 \t0.760870 \t0.760870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231096b-3f63-4239-a27a-071f1aa07c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_args = TrainingArguments(\n",
    "    output_dir=\"comrel\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=8e-5,\n",
    "    adam_epsilon=1e-5,\n",
    "    num_train_epochs=8,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.2,\n",
    "    seed=0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    label_names=[\"labels\"],\n",
    "    label_smoothing_factor=0.05,\n",
    "    weight_decay=0.03,\n",
    "    torch_compile=False,\n",
    "    eval_on_start=True,\n",
    "    group_by_length=True,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "train(tr_args)\n",
    "# Epoch \tTraining Loss \tValidation Loss \tAccuracy \tF1       \tPrecision \tRecall\n",
    "# 8 \t    0.137600 \t    0.624936 \t        0.706522 \t0.715789 \t0.693878 \t0.739130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30e0ac-e6c9-47b3-b32d-6f4bf08dd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_args = TrainingArguments(\n",
    "    output_dir=\"comrel\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-6,\n",
    "    adam_epsilon=1e-5,\n",
    "    num_train_epochs=25,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    seed=0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    label_names=[\"labels\"],\n",
    "    label_smoothing_factor=0.05,\n",
    "    weight_decay=0.05,\n",
    "    torch_compile=False,\n",
    "    eval_on_start=True,\n",
    "    group_by_length=False,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"best\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "train(tr_args, \"finetuned\")\n",
    "# Epoch \tTraining Loss \tValidation Loss \tAccuracy \tF1 \t        Precision \tRecall\n",
    "# 12 \t    0.200000 \t    0.619146        \t0.793478 \t0.804124 \t0.764706 \t0.847826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9512d-885a-40be-b41f-4fa907baeca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
