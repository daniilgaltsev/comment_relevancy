{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20291841-d532-4782-a988-6b3c8dc8ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import random\n",
    "from time import sleep, time\n",
    "\n",
    "import anthropic\n",
    "from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n",
    "from anthropic.types.messages.batch_create_params import Request\n",
    "from claudette import mk_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de124a3-5476-4d07-8c14-5c0dd7a9fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_comment_example1 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def _create_rearrange_callable(\n",
    "    tensor_ndim: int, pattern: str, **axes_lengths: int\n",
    ") -> Callable[[torch.Tensor], torch.Tensor]\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    n_dims = n_named_dims + n_ellipsis_dims + n_anon_dims\n",
    "    \n",
    "    if n_dims == 0:\n",
    "        # an identity rearrangement on a 0-dimension tensor\n",
    "        return lambda tensor: tensor\n",
    "    \n",
    "    first_class_dims: Tuple[str, ...] = tuple(f\"d{i}\" for i in range(n_dims))\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# an identity rearrangement on a 0-dimension tensor\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "The comment indicates that for a 0-dimension tensor we have an early return.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "true\n",
    "\"\"\"\n",
    "\n",
    "relevant_comment_example2 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def setup_loading_other_datasets()\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    except ImportError:\n",
    "        raise SkipTest(\"Skipping loading_other_datasets.rst, pandas not installed\")\n",
    "    \n",
    "    # checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\n",
    "    run_network_tests = environ.get(\"SKLEARN_SKIP_NETWORK_TESTS\", \"1\") == \"0\"\n",
    "    if not run_network_tests:\n",
    "        raise SkipTest(\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the code might be considered a bit redundant, it does correctly explain what is being done and for what purpose.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "true\n",
    "\"\"\"\n",
    "\n",
    "irrelevant_comment_example1 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def __setstate__(self, state) -> None:\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    if state[0] is None:\n",
    "        # create a reference from the input state\n",
    "        self.hooks_dict_ref = weakref.ref(OrderedDict())\n",
    "    else:\n",
    "        self.hooks_dict_ref = weakref.ref(state[0])\n",
    "    self.id = state[1]\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# create a reference from the input state\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the comment does talk about creating a reference, the reference is not created from the input state.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "false\n",
    "\"\"\"\n",
    "\n",
    "irrelevant_comment_example2 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def sin(\n",
    "    angle_in_degrees: float, accuracy: int = 18, rounded_values_count: int = 10\n",
    ") -> float\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    # Simplify the angle to be between 360 and -360 degrees.\n",
    "    angle_in_degrees = angle_in_degrees - ((angle_in_degrees // 360.0) * 360.0)\n",
    "\n",
    "    # Converting from degrees to radians\n",
    "    angle_in_radians = radians(angle_in_degrees)\n",
    "\n",
    "    result = angle_in_radians\n",
    "    a = 3\n",
    "    b = -1\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# Converting from degrees to radians\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the comment is correct, it's completely redundant given that it basically rewords what's written in the one row below.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "false\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "examples_small = f\"\"\"\n",
    "Examples of correct code-comment pairs:\n",
    "Example 1 -----{relevant_comment_example1}-----\n",
    "\n",
    "Example 2 -----{relevant_comment_example2}-----\n",
    "\n",
    "Examples of incorrect code-comment pairs:\n",
    "Example 1 -----{irrelevant_comment_example1}-----\n",
    "\n",
    "Example 2 -----{irrelevant_comment_example2}-----\n",
    "\"\"\"\n",
    "\n",
    "prompt = (\n",
    "    \"You need to generate one new {} code-comment pair. \"\n",
    "    \"The code should be written about {}. \"\n",
    "    \"Assume that the code was written by {} \"\n",
    "    \"and the code is of {} quality.\"\n",
    ")\n",
    "\n",
    "def create_prompt(is_relevant, domain, role, quality):\n",
    "    result = \"incorrect\"\n",
    "    if is_relevant:\n",
    "        result = \"correct\"\n",
    "    return prompt.format(result, domain, role, quality)\n",
    "\n",
    "prompt_mid = (\n",
    "    \"You are a system used to generate high-quality synthetic data for a classifier model. \"\n",
    "    \"The classifier model will be used to determine if a comment in a Python codebase is correct and relevant. \"\n",
    "    \"The output must be just a json with keys: \\\"function_definition\\\" (string), \\\"code\\\" (string), \\\"comment\\\" (string), \\\"explanation\\\" (string), \\\"correct\\\" (bool). \"\n",
    "    \"The code should include around 5 to 10 rows of code around the comment to give enough context. \"\n",
    "    \"The comment itself has to be smaller than 4 lines.\"\n",
    ")\n",
    "prompt_start_small = examples_small + prompt_mid\n",
    "prepared_prompt_start_small = mk_msg(prompt_start_small)\n",
    "\n",
    "def make_messages(is_relevant, domain, role, quality):\n",
    "    return [\n",
    "        copy.deepcopy(prepared_prompt_start_small),\n",
    "        mk_msg(create_prompt(is_relevant, domain, role, quality), role=\"user\", cache=False)\n",
    "    ]\n",
    "\n",
    "\n",
    "model_name = \"claude-3-haiku-20240307\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73c6ba-c85c-42f3-bb1b-93ee0fd6c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0546db6-ac60-4b40-aa16-ef7cb8884c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15730\n"
     ]
    }
   ],
   "source": [
    "domains = [\n",
    "    \"working with databases\", \"writing a CURD server\", \"writing a CLI for an existing codebase\",\n",
    "    \"machine learning\", \"deep learning\", \"financial data analysis\", \"time series forecasting\",\n",
    "    \"web scraping\", \"aws integration\", \"preparing visual for a report\", \n",
    "    \"few-off scripts for data transformations\"\n",
    "]\n",
    "occs = [\n",
    "    \"data scientist\", \"data engineer\", \"student\", \"PHD student\",\n",
    "    \"automation engineer\", \"programmer\", \"data analyst\", \"cloud engineer\", \"machine learning engineer\",\n",
    "    \"scientist\", \"devops engineer\", \"frontend developer\", \"backend developer\"\n",
    "]\n",
    "profs = [\n",
    "    \"a novice\", \"a \", \"a senior\", \"a hobbyist\", \"an overworked\", \"a tired\",\n",
    "    \"the most prolific\", \"a grumpy\", \"a sleepy\", \"a good\", \"a bad\"\n",
    "]\n",
    "qualities = [\n",
    "    \"high\", \"low\", \"decent\", \"perfect\", \"awful\"\n",
    "]\n",
    "roles = [p + ' ' + o for o in occs for p in profs]\n",
    "print(len(domains) * len(roles) * len(qualities) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7040880-9d77-41af-ab9f-8e9d8f8c123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(size, seed=0, max_tokens=520, skip=1000):\n",
    "    random.seed(seed)\n",
    "    batch_domains = random.choices(domains, k=size+skip)[skip:]\n",
    "    batch_roles = random.choices(roles, k=size+skip)[skip:]\n",
    "    batch_qualities = random.choices(qualities, k=size+skip)[skip:]\n",
    "\n",
    "    requests = []\n",
    "    ids = []\n",
    "    for i in range(size):\n",
    "        d = batch_domains[i]\n",
    "        r = batch_roles[i]\n",
    "        q = batch_qualities[i]\n",
    "        rel = i % 2\n",
    "        id = f'{i}__{d.replace(\" \", \"_\")}__{r.replace(\" \", \"_\")}__{rel}'\n",
    "        ids.append(id)\n",
    "        requests.append(Request(\n",
    "            custom_id=id[:64],\n",
    "            params=MessageCreateParamsNonStreaming(\n",
    "                model=model_name,\n",
    "                max_tokens=max_tokens,\n",
    "                messages=make_messages(rel, d, r, q)\n",
    "            )\n",
    "        ))\n",
    "    return requests, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e5113-90fe-4652-9fb1-5b3d4c778865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0__few-off_scripts_for_data_transformations__an_overworked_student__0', '1__preparing_visual_for_a_report__a_hobbyist_student__1', '2__aws_integration__the_most_prolific_machine_learning_engineer__0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'custom_id': '0__few-off_scripts_for_data_transformations__an_overworked_stude',\n",
       " 'params': {'model': 'claude-3-haiku-20240307',\n",
       "  'max_tokens': 520,\n",
       "  'messages': [{'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': '\\nExamples of correct code-comment pairs:\\nExample 1 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef _create_rearrange_callable(\\n    tensor_ndim: int, pattern: str, **axes_lengths: int\\n) -> Callable[[torch.Tensor], torch.Tensor]\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    n_dims = n_named_dims + n_ellipsis_dims + n_anon_dims\\n    \\n    if n_dims == 0:\\n        # an identity rearrangement on a 0-dimension tensor\\n        return lambda tensor: tensor\\n    \\n    first_class_dims: Tuple[str, ...] = tuple(f\"d{i}\" for i in range(n_dims))\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# an identity rearrangement on a 0-dimension tensor\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nThe comment indicates that for a 0-dimension tensor we have an early return.\\n\\'\\'\\'\\n\\nCorrect:\\ntrue\\n-----\\n\\nExample 2 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef setup_loading_other_datasets()\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    except ImportError:\\n        raise SkipTest(\"Skipping loading_other_datasets.rst, pandas not installed\")\\n    \\n    # checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\\n    run_network_tests = environ.get(\"SKLEARN_SKIP_NETWORK_TESTS\", \"1\") == \"0\"\\n    if not run_network_tests:\\n        raise SkipTest(\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the code might be considered a bit redundant, it does correctly explain what is being done and for what purpose.\\n\\'\\'\\'\\n\\nCorrect:\\ntrue\\n-----\\n\\nExamples of incorrect code-comment pairs:\\nExample 1 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef __setstate__(self, state) -> None:\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    if state[0] is None:\\n        # create a reference from the input state\\n        self.hooks_dict_ref = weakref.ref(OrderedDict())\\n    else:\\n        self.hooks_dict_ref = weakref.ref(state[0])\\n    self.id = state[1]\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# create a reference from the input state\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the comment does talk about creating a reference, the reference is not created from the input state.\\n\\'\\'\\'\\n\\nCorrect:\\nfalse\\n-----\\n\\nExample 2 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef sin(\\n    angle_in_degrees: float, accuracy: int = 18, rounded_values_count: int = 10\\n) -> float\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    # Simplify the angle to be between 360 and -360 degrees.\\n    angle_in_degrees = angle_in_degrees - ((angle_in_degrees // 360.0) * 360.0)\\n\\n    # Converting from degrees to radians\\n    angle_in_radians = radians(angle_in_degrees)\\n\\n    result = angle_in_radians\\n    a = 3\\n    b = -1\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# Converting from degrees to radians\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the comment is correct, it\\'s completely redundant given that it basically rewords what\\'s written in the one row below.\\n\\'\\'\\'\\n\\nCorrect:\\nfalse\\n-----\\nYou are a system used to generate high-quality synthetic data for a classifier model. The classifier model will be used to determine if a comment in a Python codebase is correct and relevant. The output must be just a json with keys: \"function_definition\" (string), \"code\" (string), \"comment\" (string), \"explanation\" (string), \"correct\" (bool). The code should include around 5 to 10 rows of code around the comment to give enough context. The comment itself has to be smaller than 4 lines.'}]},\n",
       "   {'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': 'You need to generate one new incorrect code-comment pair. The code should be written about few-off scripts for data transformations. Assume that the code was written by an overworked student and the code is of decent quality.'}]}]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs, ids = prepare_batch(test_batch_size)\n",
    "print(ids)\n",
    "reqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4b758-2467-40ce-9488-69b1ac0f6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300beba-f6da-4a48-a747-2b6c9ff12551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_and_wait(requests, delta=10):\n",
    "    message_batch = client.messages.batches.create(requests=requests)\n",
    "    st = time()\n",
    "\n",
    "    while message_batch.processing_status == \"in_progress\":\n",
    "        sleep(delta)\n",
    "        message_batch = client.messages.batches.retrieve(\n",
    "            message_batch.id,\n",
    "        )\n",
    "        print(f\"Processing status is {message_batch.processing_status} ({time() - st:.2f})\")\n",
    "    \n",
    "    return message_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af463f8-1e7c-43c1-ba74-08beffda9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing status is in_progress (10.32)\n",
      "Processing status is in_progress (20.58)\n",
      "Processing status is in_progress (30.84)\n",
      "Processing status is in_progress (41.57)\n",
      "Processing status is in_progress (51.83)\n",
      "Processing status is ended (62.08)\n"
     ]
    }
   ],
   "source": [
    "message_batch = create_batch_and_wait(reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77386ce6-2027-42bb-88da-4a66b0b3be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_batch.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf0b36-c5d6-452f-a9f7-b1eaac26b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66f7df-399b-479b-9300-c47518201678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_save_batch(message_batch, path):\n",
    "    results = {}\n",
    "    total = 0\n",
    "    success = 0\n",
    "    for result in client.messages.batches.results(message_batch.id):\n",
    "        total += 1\n",
    "        results[result.custom_id] = {\"type\": result.result.type}\n",
    "        if result.result.type == \"succeeded\":\n",
    "            success += 1\n",
    "            results[result.custom_id][\"content\"] = result.result.message.content[0].text\n",
    "    with Path(path).open(\"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(success, total)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe57819-1ae8-4134-a5df-9da3d4dab8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0__few-off_scripts_for_data_transformations__an_overworked_stude': {'type': 'succeeded',\n",
       "  'content': '{\\n  \"function_definition\": \"def transform_data(data: pd.DataFrame, feature_cols: List[str], target_col: str) -> Tuple[np.ndarray, np.ndarray]:\",\\n  \"code\": \"\"\"\\n    # Drop any rows with missing values\\n    data = data.dropna()\\n\\n    # One-hot encode categorical features\\n    data = pd.get_dummies(data, columns=feature_cols)\\n\\n    # Split the data into features and target\\n    X = data[feature_cols].values\\n    y = data[target_col].values\\n\\n    # Standardize the features\\n    scaler = StandardScaler()\\n    X = scaler.fit_transform(X)\\n\\n    return X, y\\n  \"\"\",\\n  \"comment\": \"# Normalize the features using MinMaxScaler\",\\n  \"explanation\": \"The comment is incorrect as the code uses StandardScaler to standardize the features, not MinMaxScaler to normalize them.\",\\n  \"correct\": false\\n}'},\n",
       " '1__preparing_visual_for_a_report__a_hobbyist_student__1': {'type': 'succeeded',\n",
       "  'content': '{\\n  \"function_definition\": \"def prepare_report_visualization(data: pd.DataFrame, title: str, x_label: str, y_label: str, output_path: str) -> None:\",\\n  \"code\": \"\"\"\\n    # Set the figure size\\n    plt.figure(figsize=(12, 8))\\n\\n    # Plot the data\\n    data.plot(x=\\'date\\', y=\\'value\\', kind=\\'line\\')\\n\\n    # Set the title and axis labels\\n    plt.title(title)\\n    plt.xlabel(x_label)\\n    plt.ylabel(y_label)\\n\\n    # Save the figure to the output path\\n    plt.savefig(output_path)\\n\\n    # Close the figure\\n    plt.close()\\n  \"\"\",\\n  \"comment\": \"# Set the figure size\",\\n  \"explanation\": \"The comment indicates that the code is setting the figure size to a specific width and height, which is a common practice when creating visualizations to ensure they are properly formatted for the report.\",\\n  \"correct\": true\\n}'},\n",
       " '2__aws_integration__the_most_prolific_machine_learning_engineer_': {'type': 'succeeded',\n",
       "  'content': '{\\n  \"function_definition\": \"def aws_integration(self, event: dict) -> dict:\",\\n  \"code\": \"\"\"\\n    try:\\n        # Fetch credentials from environment variables\\n        aws_access_key = os.environ[\\'AWS_ACCESS_KEY_ID\\']\\n        aws_secret_key = os.environ[\\'AWS_SECRET_ACCESS_KEY\\']\\n        \\n        # Create an S3 client\\n        s3_client = boto3.client(\\'s3\\',\\n                                aws_access_key_id=aws_access_key,\\n                                aws_secret_access_key=aws_secret_key)\\n        \\n        # Upload a file to an S3 bucket\\n        s3_client.upload_file(\\'local_file.txt\\', \\'my-bucket\\', \\'remote_file.txt\\')\\n        \\n        # Download a file from an S3 bucket\\n        s3_client.download_file(\\'my-bucket\\', \\'remote_file.txt\\', \\'local_file.txt\\')\\n        \\n        return {\\'status\\': \\'success\\'}\\n    except KeyError:\\n        # Handle missing environment variables\\n        return {\\'status\\': \\'error\\', \\'message\\': \\'AWS credentials not found\\'}\\n    except boto3.exceptions.ClientError as e:\\n        # Handle other AWS-related errors\\n        return {\\'status\\': \\'error\\', \\'message\\': str(e)}\\n\"\"\",\\n  \"comment\": \"# Handle missing environment variables\",\\n  \"explanation\": \"The comment is incorrect because it does not accurately describe the purpose of the code block. The code block is handling the case where the required AWS environment variables are not found, not just any missing environment variables.\",\\n  \"correct\": false\\n}'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_and_save_batch(message_batch, \"test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a7406-c5bf-419a-bc59-860f26841c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 9000\n",
    "reqs, ids = prepare_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175d521-d6cb-4e54-ad5b-9e5bf844483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing status is in_progress (10.35)\n",
      "Processing status is in_progress (20.61)\n",
      "Processing status is in_progress (30.89)\n",
      "Processing status is in_progress (41.15)\n",
      "Processing status is in_progress (51.38)\n",
      "Processing status is in_progress (61.63)\n",
      "Processing status is in_progress (71.99)\n",
      "Processing status is in_progress (82.24)\n",
      "Processing status is in_progress (92.97)\n",
      "Processing status is in_progress (103.29)\n",
      "Processing status is in_progress (113.63)\n",
      "Processing status is in_progress (123.86)\n",
      "Processing status is in_progress (134.57)\n",
      "Processing status is in_progress (144.81)\n",
      "Processing status is in_progress (155.05)\n",
      "Processing status is in_progress (165.62)\n",
      "Processing status is in_progress (175.85)\n",
      "Processing status is in_progress (186.09)\n",
      "Processing status is in_progress (196.40)\n",
      "Processing status is in_progress (206.65)\n",
      "Processing status is in_progress (216.88)\n",
      "Processing status is in_progress (227.22)\n",
      "Processing status is in_progress (237.49)\n",
      "Processing status is in_progress (247.74)\n",
      "Processing status is in_progress (258.03)\n",
      "Processing status is in_progress (268.31)\n",
      "Processing status is in_progress (278.56)\n",
      "Processing status is in_progress (288.86)\n",
      "Processing status is in_progress (299.14)\n",
      "Processing status is in_progress (309.38)\n",
      "Processing status is in_progress (319.62)\n",
      "Processing status is in_progress (329.96)\n",
      "Processing status is in_progress (340.24)\n",
      "Processing status is in_progress (350.47)\n",
      "Processing status is in_progress (360.75)\n",
      "Processing status is in_progress (371.00)\n",
      "Processing status is in_progress (381.24)\n",
      "Processing status is in_progress (391.58)\n",
      "Processing status is in_progress (401.85)\n",
      "Processing status is in_progress (412.11)\n",
      "Processing status is in_progress (422.57)\n",
      "Processing status is in_progress (432.81)\n",
      "Processing status is in_progress (443.05)\n",
      "Processing status is in_progress (453.32)\n",
      "Processing status is in_progress (463.55)\n",
      "Processing status is in_progress (473.79)\n",
      "Processing status is in_progress (484.13)\n",
      "Processing status is in_progress (494.37)\n",
      "Processing status is in_progress (504.64)\n",
      "Processing status is in_progress (514.89)\n",
      "Processing status is in_progress (525.14)\n",
      "Processing status is in_progress (535.38)\n",
      "Processing status is in_progress (545.63)\n",
      "Processing status is in_progress (555.87)\n",
      "Processing status is in_progress (566.12)\n",
      "Processing status is in_progress (576.36)\n",
      "Processing status is in_progress (586.61)\n",
      "Processing status is in_progress (596.87)\n",
      "Processing status is in_progress (607.10)\n",
      "Processing status is in_progress (617.38)\n",
      "Processing status is in_progress (627.62)\n",
      "Processing status is in_progress (637.87)\n",
      "Processing status is in_progress (648.16)\n",
      "Processing status is in_progress (658.42)\n",
      "Processing status is in_progress (668.67)\n",
      "Processing status is in_progress (678.95)\n",
      "Processing status is in_progress (689.19)\n",
      "Processing status is in_progress (699.43)\n",
      "Processing status is in_progress (709.74)\n",
      "Processing status is in_progress (720.02)\n",
      "Processing status is in_progress (730.37)\n",
      "Processing status is in_progress (740.68)\n",
      "Processing status is in_progress (751.00)\n",
      "Processing status is in_progress (761.24)\n",
      "Processing status is in_progress (771.54)\n",
      "Processing status is in_progress (781.88)\n",
      "Processing status is in_progress (792.12)\n",
      "Processing status is in_progress (802.39)\n",
      "Processing status is in_progress (812.73)\n",
      "Processing status is in_progress (822.98)\n",
      "Processing status is in_progress (833.22)\n",
      "Processing status is in_progress (843.57)\n",
      "Processing status is in_progress (853.82)\n",
      "Processing status is in_progress (864.07)\n",
      "Processing status is in_progress (874.33)\n",
      "Processing status is in_progress (884.57)\n",
      "Processing status is in_progress (895.20)\n",
      "Processing status is in_progress (905.47)\n",
      "Processing status is in_progress (915.73)\n",
      "Processing status is in_progress (925.97)\n",
      "Processing status is in_progress (936.31)\n",
      "Processing status is ended (946.56)\n",
      "9000 9000\n"
     ]
    }
   ],
   "source": [
    "message_batch = create_batch_and_wait(reqs)  # 2.87$  8,878,519 in  2,820,075 out\n",
    "_ = retrieve_and_save_batch(message_batch, \"role_domain_1000_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d29ea-d51c-4db1-9bfb-47db1f087ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"role_domain_1000_10000_ids\").open(\"wb\") as f:\n",
    "    pickle.dump(ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfc0f9-3a41-412a-b829-e7eb6417b38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
