{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "path = \"/content/drive/MyDrive/Deep Learning/comrel/finetuned\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"[SEP]\"\n",
    "\n",
    "def prepare_input(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"function_definition\"] + sep + example[\"code\"] + sep + example[\"comment\"],\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def parse_text(text):\n",
    "    # NOTE: Doesn't collect comments and function definitions correctly\n",
    "    inputs = []\n",
    "    defs = []\n",
    "    tree = ast.parse(text)\n",
    "    for el in tree.body:\n",
    "        if isinstance(el, ast.FunctionDef):\n",
    "            defs.append((el.lineno - 1, el.end_lineno - 1, el.col_offset))\n",
    "\n",
    "    inputs = []\n",
    "    lines = text.split('\\n')\n",
    "    for lineno, line in enumerate(lines):\n",
    "        if (offset := line.find('#')) != -1:\n",
    "            corresponding_def = None\n",
    "            for (def_l, def_el, def_off) in defs:\n",
    "                if def_l <= lineno and def_off <= offset:\n",
    "                    corresponding_def = (def_l, def_el, def_off)\n",
    "\n",
    "            comment = line[offset:]\n",
    "            code = '\\n'.join(lines[lineno - 4:lineno + 4])\n",
    "            fdef = \"None\"\n",
    "            if corresponding_def is not None:\n",
    "                fdef = [lines[corresponding_def[0]][corresponding_def[2]:]]\n",
    "                cur_lineno = corresponding_def[0]\n",
    "                while cur_lineno <= corresponding_def[1]:\n",
    "                    if lines[cur_lineno].find(\"):\") != -1 or lines[cur_lineno].find(\"->\") != -1:\n",
    "                        fdef += lines[corresponding_def[0] + 1:cur_lineno + 1]\n",
    "                        break\n",
    "                    cur_lineno += 1\n",
    "\n",
    "                fdef = '\\n'.join(fdef).strip()\n",
    "\n",
    "            inputs.append({\n",
    "                \"function_definition\": fdef,\n",
    "                \"code\": code,\n",
    "                \"comment\": comment,\n",
    "                \"lineno\": lineno\n",
    "            })\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def predict(inp, model=model):\n",
    "    with torch.no_grad():\n",
    "        out = model(**inp)\n",
    "    return nn.functional.softmax(out.logits, dim=-1)[0, 1].item()\n",
    "\n",
    "\n",
    "def parse_and_predict(text, thrd=0.0):\n",
    "    parsed = parse_text(text)\n",
    "    preds = [predict(prepare_input(p)) for p in parsed]\n",
    "    result = []\n",
    "    for i, p in enumerate(preds):\n",
    "        if thrd > 0:\n",
    "            p = thrd > p\n",
    "        result.append((parsed[i][\"lineno\"], p))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_and_predict_file(path, thrd=0.0):\n",
    "    text = Path(path).open(\"r\").read()\n",
    "    return parse_and_predict(text, thrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, False), (48, False), (54, False), (55, False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_and_predict_file(\"example.py\", 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 0.9996256828308105),\n",
       " (48, 0.9997977614402771),\n",
       " (54, 0.9949824810028076),\n",
       " (55, 0.9992367029190063)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_and_predict_file(\"example.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Path(\"example.py\").open(\"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment on line 54 is incorrect: '        # decorator usage like @_disable_dynamo(recursive=False). The resulting'.\n",
      "\n",
      "The comment on line 42 is estimated to be correct with probability 1.00: '            # cache this on the first invocation to avoid adding too much overhead.'.\n",
      "The comment on line 48 is estimated to be correct with probability 1.00: '                fn.__dynamo_disable = disable_fn  # type: ignore[attr-defined]'.\n",
      "The comment on line 54 is estimated to be correct with probability 0.99: '        # decorator usage like @_disable_dynamo(recursive=False). The resulting'.\n",
      "The comment on line 55 is estimated to be correct with probability 1.00: '        # object expects the original decorated function as the arg.'.\n"
     ]
    }
   ],
   "source": [
    "def parse_and_predict_pretty_out(text, thrd=0.0):\n",
    "    results = parse_and_predict(text, thrd=thrd)\n",
    "    lines = text.split('\\n')\n",
    "    output = []\n",
    "    if thrd > 0:\n",
    "        for lineno, do_warn in results:\n",
    "            if do_warn:\n",
    "                output.append(f\"The comment on line {lineno} is incorrect: '{lines[lineno]}'.\")\n",
    "    else:\n",
    "        for lineno, p in results:\n",
    "            output.append(f\"The comment on line {lineno} is estimated to be correct with probability {p:.2f}: '{lines[lineno]}'.\")\n",
    "    return '\\n'.join(output)\n",
    "\n",
    "print(parse_and_predict_pretty_out(text, 0.995))\n",
    "print()\n",
    "print(parse_and_predict_pretty_out(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"a = 3\n",
    "b = 2\n",
    "# The code below does some calculations based on a predefined rule that is very important\n",
    "c = a - b  # Calculate and store the sum of a and b in c\n",
    "d = a + b  # Calculate and store the sum of a and b in d\n",
    "e = c * b  # Calculate and store the product of c and d in e\n",
    "print(f\"Wow, maths: {[a, b, c, d, e]}\")\"\"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=parse_and_predict_pretty_out,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Input\", lines=7),\n",
    "        gr.Slider(value=0.8, minimum=0.0, maximum=1.0, step=0.05)],\n",
    "    outputs=[gr.Textbox(label=\"Predictions\", lines=7)],\n",
    "    examples=[[example_text, 0.0], [example_text, 0.53]],\n",
    "    title=\"Comment \\\"Correctness\\\" Classifier\",\n",
    "    description='Calculates probabilities for each comment in text to be \"correct\"/\"relevant\". If the threshold is 0, outputs raw predictions. Otherwise, will report only \"incorrect\" comments.'\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
