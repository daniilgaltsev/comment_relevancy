{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59641bf-70ef-4b3e-9766-e9e27d531461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import random\n",
    "from time import sleep, time\n",
    "\n",
    "import anthropic\n",
    "from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n",
    "from anthropic.types.messages.batch_create_params import Request\n",
    "from claudette import mk_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e63bd7-7d22-4825-b236-578b90b74b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_comment_example1 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def _create_rearrange_callable(\n",
    "    tensor_ndim: int, pattern: str, **axes_lengths: int\n",
    ") -> Callable[[torch.Tensor], torch.Tensor]\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    n_dims = n_named_dims + n_ellipsis_dims + n_anon_dims\n",
    "    \n",
    "    if n_dims == 0:\n",
    "        # an identity rearrangement on a 0-dimension tensor\n",
    "        return lambda tensor: tensor\n",
    "    \n",
    "    first_class_dims: Tuple[str, ...] = tuple(f\"d{i}\" for i in range(n_dims))\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# an identity rearrangement on a 0-dimension tensor\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "The comment indicates that for a 0-dimension tensor we have an early return.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "true\n",
    "\"\"\"\n",
    "\n",
    "relevant_comment_example2 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def setup_loading_other_datasets()\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    except ImportError:\n",
    "        raise SkipTest(\"Skipping loading_other_datasets.rst, pandas not installed\")\n",
    "    \n",
    "    # checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\n",
    "    run_network_tests = environ.get(\"SKLEARN_SKIP_NETWORK_TESTS\", \"1\") == \"0\"\n",
    "    if not run_network_tests:\n",
    "        raise SkipTest(\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the code might be considered a bit redundant, it does correctly explain what is being done and for what purpose.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "true\n",
    "\"\"\"\n",
    "\n",
    "irrelevant_comment_example1 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def __setstate__(self, state) -> None:\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    if state[0] is None:\n",
    "        # create a reference from the input state\n",
    "        self.hooks_dict_ref = weakref.ref(OrderedDict())\n",
    "    else:\n",
    "        self.hooks_dict_ref = weakref.ref(state[0])\n",
    "    self.id = state[1]\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# create a reference from the input state\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the comment does talk about creating a reference, the reference is not created from the input state.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "false\n",
    "\"\"\"\n",
    "\n",
    "irrelevant_comment_example2 =\\\n",
    "\"\"\"\n",
    "Function Definition:\n",
    "'''\n",
    "def sin(\n",
    "    angle_in_degrees: float, accuracy: int = 18, rounded_values_count: int = 10\n",
    ") -> float\n",
    "'''\n",
    "\n",
    "Code:\n",
    "'''\n",
    "    # Simplify the angle to be between 360 and -360 degrees.\n",
    "    angle_in_degrees = angle_in_degrees - ((angle_in_degrees // 360.0) * 360.0)\n",
    "\n",
    "    # Converting from degrees to radians\n",
    "    angle_in_radians = radians(angle_in_degrees)\n",
    "\n",
    "    result = angle_in_radians\n",
    "    a = 3\n",
    "    b = -1\n",
    "'''\n",
    "\n",
    "Comment:\n",
    "'''\n",
    "# Converting from degrees to radians\n",
    "'''\n",
    "\n",
    "Explanation:\n",
    "'''\n",
    "While the comment is correct, it's completely redundant given that it basically rewords what's written in the one row below.\n",
    "'''\n",
    "\n",
    "Correct:\n",
    "false\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "examples_small = f\"\"\"\n",
    "Examples of correct code-comment pairs:\n",
    "Example 1 -----{relevant_comment_example1}-----\n",
    "\n",
    "Example 2 -----{relevant_comment_example2}-----\n",
    "\n",
    "Examples of incorrect code-comment pairs:\n",
    "Example 1 -----{irrelevant_comment_example1}-----\n",
    "\n",
    "Example 2 -----{irrelevant_comment_example2}-----\n",
    "\"\"\"\n",
    "\n",
    "prompt = (\n",
    "    \"You need to generate one new {} code-comment pair. \"\n",
    "    \"The code should be written about {}. \"\n",
    "    \"Assume that the code was written by {}.\"\n",
    ")\n",
    "\n",
    "def create_prompt(is_relevant, domain, role):\n",
    "    result = \"incorrect\"\n",
    "    if is_relevant:\n",
    "        result = \"correct\"\n",
    "    return prompt.format(result, domain, role)\n",
    "\n",
    "prompt_mid = (\n",
    "    \"You are a system used to generate high-quality synthetic data for a classifier model. \"\n",
    "    \"The classifier model will be used to determine if a comment in a Python codebase is correct and relevant. \"\n",
    "    \"The output must be just a json with keys: \\\"function_definition\\\" (string), \\\"code\\\" (string), \\\"comment\\\" (string), \\\"explanation\\\" (string), \\\"correct\\\" (bool). \"\n",
    "    \"The code should include around 5 to 10 rows of code around the comment to give enough context. \"\n",
    "    \"The comment itself has to be smaller than 4 lines.\"\n",
    ")\n",
    "prompt_start_small = examples_small + prompt_mid\n",
    "prepared_prompt_start_small = mk_msg(prompt_start_small)\n",
    "\n",
    "def make_messages(is_relevant, domain, role):\n",
    "    return [\n",
    "        copy.deepcopy(prepared_prompt_start_small),\n",
    "        mk_msg(create_prompt(is_relevant, domain, role), role=\"user\", cache=False)\n",
    "    ]\n",
    "\n",
    "\n",
    "model_name = \"claude-3-haiku-20240307\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bf5a7-f058-4ca4-a97b-fcbac6e7dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42822a41-9ce1-4e24-b1b3-cc6de5075de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146\n"
     ]
    }
   ],
   "source": [
    "domains = [\n",
    "    \"working with databases\", \"writing a CURD server\", \"writing a CLI for an existing codebase\",\n",
    "    \"machine learning\", \"deep learning\", \"financial data analysis\", \"time series forecasting\",\n",
    "    \"web scraping\", \"aws integration\", \"preparing visual for a report\", \n",
    "    \"few-off scripts for data tranformations\"\n",
    "]\n",
    "occs = [\n",
    "    \"data scientist\", \"data engineer\", \"student\", \"PHD student\",\n",
    "    \"automation engineer\", \"programmer\", \"data analyst\", \"cloud engineer\", \"machine learning engineer\",\n",
    "    \"scientist\", \"devops engineer\", \"frontend developer\", \"backend developer\"\n",
    "]\n",
    "profs = [\n",
    "    \"a novice\", \"a \", \"a senior\", \"a hobbyist\", \"an overworked\", \"a tired\",\n",
    "    \"the most prolific\", \"a grumpy\", \"a sleepy\", \"a good\", \"a bad\"\n",
    "]\n",
    "roles = [p + ' ' + o for o in occs for p in profs]\n",
    "print(len(domains) * len(roles) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae8287-77b7-4365-b673-5a37da50f2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(len, roles)) + max(map(len, roles)) + 4 + 2 + 1 + 2 + 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddd89c-e3d6-461a-bf83-c884f95b5fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a good', 'a sleepy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "random.choices(profs, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a6551-8d4c-42a6-a7d3-d623c292723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi_hi_hi'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hi hi hi\".replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8811416-4747-4ff4-be3e-56f700b6802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(size, seed=0, max_tokens=520):\n",
    "    random.seed(seed)\n",
    "    batch_domains = random.choices(domains, k=size)\n",
    "    batch_roles = random.choices(roles, k=size)\n",
    "\n",
    "    requests = []\n",
    "    ids = []\n",
    "    for i in range(size):\n",
    "        d = batch_domains[i]\n",
    "        r = batch_roles[i]\n",
    "        rel = i % 2\n",
    "        id = f'{i}__{d.replace(\" \", \"_\")}__{r.replace(\" \", \"_\")}__{rel}'\n",
    "        ids.append(id)\n",
    "        requests.append(Request(\n",
    "            custom_id=id[:64],\n",
    "            params=MessageCreateParamsNonStreaming(\n",
    "                model=model_name,\n",
    "                max_tokens=max_tokens,\n",
    "                messages=make_messages(rel, d, r)\n",
    "            )\n",
    "        ))\n",
    "    return requests, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b9701-80de-44bb-b1a5-b7cba67e5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0__preparing_visual_for_a_report__an_overworked_PHD_student__0', '1__aws_integration__a_grumpy_data_analyst__1', '2__deep_learning__a_senior_programmer__0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'custom_id': '0__preparing_visual_for_a_report__an_overworked_PHD_student__0',\n",
       " 'params': {'model': 'claude-3-haiku-20240307',\n",
       "  'max_tokens': 520,\n",
       "  'messages': [{'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': '\\nExamples of correct code-comment pairs:\\nExample 1 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef _create_rearrange_callable(\\n    tensor_ndim: int, pattern: str, **axes_lengths: int\\n) -> Callable[[torch.Tensor], torch.Tensor]\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    n_dims = n_named_dims + n_ellipsis_dims + n_anon_dims\\n    \\n    if n_dims == 0:\\n        # an identity rearrangement on a 0-dimension tensor\\n        return lambda tensor: tensor\\n    \\n    first_class_dims: Tuple[str, ...] = tuple(f\"d{i}\" for i in range(n_dims))\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# an identity rearrangement on a 0-dimension tensor\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nThe comment indicates that for a 0-dimension tensor we have an early return.\\n\\'\\'\\'\\n\\nCorrect:\\ntrue\\n-----\\n\\nExample 2 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef setup_loading_other_datasets()\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    except ImportError:\\n        raise SkipTest(\"Skipping loading_other_datasets.rst, pandas not installed\")\\n    \\n    # checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\\n    run_network_tests = environ.get(\"SKLEARN_SKIP_NETWORK_TESTS\", \"1\") == \"0\"\\n    if not run_network_tests:\\n        raise SkipTest(\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# checks SKLEARN_SKIP_NETWORK_TESTS to see if test should run\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the code might be considered a bit redundant, it does correctly explain what is being done and for what purpose.\\n\\'\\'\\'\\n\\nCorrect:\\ntrue\\n-----\\n\\nExamples of incorrect code-comment pairs:\\nExample 1 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef __setstate__(self, state) -> None:\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    if state[0] is None:\\n        # create a reference from the input state\\n        self.hooks_dict_ref = weakref.ref(OrderedDict())\\n    else:\\n        self.hooks_dict_ref = weakref.ref(state[0])\\n    self.id = state[1]\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# create a reference from the input state\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the comment does talk about creating a reference, the reference is not created from the input state.\\n\\'\\'\\'\\n\\nCorrect:\\nfalse\\n-----\\n\\nExample 2 -----\\nFunction Definition:\\n\\'\\'\\'\\ndef sin(\\n    angle_in_degrees: float, accuracy: int = 18, rounded_values_count: int = 10\\n) -> float\\n\\'\\'\\'\\n\\nCode:\\n\\'\\'\\'\\n    # Simplify the angle to be between 360 and -360 degrees.\\n    angle_in_degrees = angle_in_degrees - ((angle_in_degrees // 360.0) * 360.0)\\n\\n    # Converting from degrees to radians\\n    angle_in_radians = radians(angle_in_degrees)\\n\\n    result = angle_in_radians\\n    a = 3\\n    b = -1\\n\\'\\'\\'\\n\\nComment:\\n\\'\\'\\'\\n# Converting from degrees to radians\\n\\'\\'\\'\\n\\nExplanation:\\n\\'\\'\\'\\nWhile the comment is correct, it\\'s completely redundant given that it basically rewords what\\'s written in the one row below.\\n\\'\\'\\'\\n\\nCorrect:\\nfalse\\n-----\\nYou are a system used to generate high-quality synthetic data for a classifier model. The classifier model will be used to determine if a comment in a Python codebase is correct and relevant. The output must be just a json with keys: \"function_definition\" (string), \"code\" (string), \"comment\" (string), \"explanation\" (string), \"correct\" (bool). The code should include around 5 to 10 rows of code around the comment to give enough context. The comment itself has to be smaller than 4 lines.'}]},\n",
       "   {'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': 'You need to generate one new incorrect code-comment pair. The code should be written about preparing visual for a report. Assume that the code was written by an overworked PHD student.'}]}]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs, ids = prepare_batch(test_batch_size)\n",
    "print(ids)\n",
    "reqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84549376-33a6-4ad3-bdd6-92d4f2aa9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da040a-686f-4937-9edd-1343368a38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_and_wait(requests, delta=10):\n",
    "    message_batch = client.messages.batches.create(requests=requests)\n",
    "    st = time()\n",
    "\n",
    "    while message_batch.processing_status == \"in_progress\":\n",
    "        sleep(delta)\n",
    "        message_batch = client.messages.batches.retrieve(\n",
    "            message_batch.id,\n",
    "        )\n",
    "        print(f\"Processing status is {message_batch.processing_status} ({time() - st:.2f})\")\n",
    "    \n",
    "    return message_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7da5a-98ef-4741-b794-7ac37129a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing status is in_progress (10.35)\n",
      "Processing status is in_progress (20.97)\n",
      "Processing status is in_progress (31.31)\n",
      "Processing status is in_progress (41.59)\n",
      "Processing status is in_progress (52.19)\n",
      "Processing status is in_progress (62.80)\n",
      "Processing status is ended (73.04)\n"
     ]
    }
   ],
   "source": [
    "message_batch = create_batch_and_wait(reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5151188-55f3-4b9b-8c69-e723ee4742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_batch.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69a20d-fa6f-43f6-b894-83a69bed6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac42cb-b5cc-411c-8dbc-2e14fc172d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_save_batch(message_batch, path):\n",
    "    results = {}\n",
    "    total = 0\n",
    "    success = 0\n",
    "    for result in client.messages.batches.results(message_batch.id):\n",
    "        total += 1\n",
    "        results[result.custom_id] = {\"type\": result.result.type}\n",
    "        if result.result.type == \"succeeded\":\n",
    "            success += 1\n",
    "            results[result.custom_id][\"content\"] = result.result.message.content[0].text\n",
    "    with Path(path).open(\"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(success, total)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18beff-607e-489d-abb3-12483df2a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0__preparing_visual_for_a_report__an_overworked_PHD_student__0': {'type': 'succeeded',\n",
       "  'content': 'Here is an example of an incorrect code-comment pair:\\n\\n{\\n  \"function_definition\": \"\"\"\\ndef generate_report_visualizations(data: pd.DataFrame, output_path: str) -> None:\\n\"\"\",\\n  \"code\": \"\"\"\\n    # Set up the figure and axes\\n    fig, ax = plt.subplots(figsize=(12, 8))\\n\\n    # Plot the data\\n    ax.plot(data[\\'x\\'], data[\\'y\\'])\\n\\n    # Save the figure\\n    plt.savefig(output_path)\\n\\n    # Close the figure\\n    plt.close()\\n\\n    # This is a really important step, so make sure you don\\'t forget it!\\n    print(\"Visualization saved to:\", output_path)\\n\"\"\",\\n  \"comment\": \"\"\"\\n# This is a really important step, so make sure you don\\'t forget it!\\n\"\"\",\\n  \"explanation\": \"The comment is incorrect because the step it refers to (closing the figure) is not the most important step in the function. The most important step is actually saving the figure to the output path, which is already covered by the previous comment.\",\\n  \"correct\": false\\n}'},\n",
       " '1__aws_integration__a_grumpy_data_analyst__1': {'type': 'succeeded',\n",
       "  'content': 'Here is a new correct code-comment pair for a Python function related to AWS integration:\\n\\n{\\n  \"function_definition\": \"def upload_file_to_s3(filename: str, bucket_name: str, key: str) -> None:\",\\n  \"code\": \"\"\"\\n    import boto3\\n\\n    s3 = boto3.client(\\'s3\\')\\n\\n    try:\\n        s3.upload_file(filename, bucket_name, key)\\n        print(f\\'Uploaded {filename} to S3 bucket {bucket_name}\\')\\n    except Exception as e:\\n        print(f\\'Error uploading {filename} to S3: {e}\\')\\n        raise e\\n    \"\"\",\\n  \"comment\": \"# Upload a local file to an S3 bucket\",\\n  \"explanation\": \"The comment accurately describes the purpose of the function, which is to upload a local file to an S3 bucket.\",\\n  \"correct\": true\\n}'},\n",
       " '2__deep_learning__a_senior_programmer__0': {'type': 'succeeded',\n",
       "  'content': '{\\n  \"function_definition\": \"def train_model(self, train_data, val_data, epochs=100, batch_size=32, learning_rate=0.001):\",\\n  \"code\": \"    for epoch in range(epochs):\\n        for batch in range(0, len(train_data), batch_size):\\n            batch_data = train_data[batch:batch+batch_size]\\n            batch_labels = train_labels[batch:batch+batch_size]\\n            \\n            # Compute the loss and gradients\\n            loss, grads = self.compute_loss_and_grads(batch_data, batch_labels)\\n            \\n            # Update the model parameters\\n            self.optimizer.update_params(learning_rate, grads)\\n        \\n        # Evaluate the model on the validation set\\n        val_loss = self.evaluate(val_data, val_labels)\\n        print(f\\'Epoch {epoch}: Train loss={loss:.4f}, Val loss={val_loss:.4f}\\')\\n    \\n    return self\",\\n  \"comment\": \"# Compute the loss and gradients\",\\n  \"explanation\": \"The comment is incorrect because it does not accurately describe what the code is doing. The code is not only computing the loss and gradients, but also updating the model parameters using the optimizer.\",\\n  \"correct\": false\\n}'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_and_save_batch(message_batch, \"test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ec9df-81ed-4233-be16-e27e2b82cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0__preparing_visual_for_a_report__an_overworked_PHD_student__0': {'type': 'succeeded', 'content': 'Here is an example of an incorrect code-comment pair:\\n\\n{\\n  \"function_definition\": \"\"\"\\ndef generate_report_visualizations(data: pd.DataFrame, output_path: str) -> None:\\n\"\"\",\\n  \"code\": \"\"\"\\n    # Set up the figure and axes\\n    fig, ax = plt.subplots(figsize=(12, 8))\\n\\n    # Plot the data\\n    ax.plot(data[\\'x\\'], data[\\'y\\'])\\n\\n    # Save the figure\\n    plt.savefig(output_path)\\n\\n    # Close the figure\\n    plt.close()\\n\\n    # This is a really important step, so make sure you don\\'t forget it!\\n    print(\"Visualization saved to:\", output_path)\\n\"\"\",\\n  \"comment\": \"\"\"\\n# This is a really important step, so make sure you don\\'t forget it!\\n\"\"\",\\n  \"explanation\": \"The comment is incorrect because the step it refers to (closing the figure) is not the most important step in the function. The most important step is actually saving the figure to the output path, which is already covered by the previous comment.\",\\n  \"correct\": false\\n}'}, '1__aws_integration__a_grumpy_data_analyst__1': {'type': 'succeeded', 'content': 'Here is a new correct code-comment pair for a Python function related to AWS integration:\\n\\n{\\n  \"function_definition\": \"def upload_file_to_s3(filename: str, bucket_name: str, key: str) -> None:\",\\n  \"code\": \"\"\"\\n    import boto3\\n\\n    s3 = boto3.client(\\'s3\\')\\n\\n    try:\\n        s3.upload_file(filename, bucket_name, key)\\n        print(f\\'Uploaded {filename} to S3 bucket {bucket_name}\\')\\n    except Exception as e:\\n        print(f\\'Error uploading {filename} to S3: {e}\\')\\n        raise e\\n    \"\"\",\\n  \"comment\": \"# Upload a local file to an S3 bucket\",\\n  \"explanation\": \"The comment accurately describes the purpose of the function, which is to upload a local file to an S3 bucket.\",\\n  \"correct\": true\\n}'}, '2__deep_learning__a_senior_programmer__0': {'type': 'succeeded', 'content': '{\\n  \"function_definition\": \"def train_model(self, train_data, val_data, epochs=100, batch_size=32, learning_rate=0.001):\",\\n  \"code\": \"    for epoch in range(epochs):\\n        for batch in range(0, len(train_data), batch_size):\\n            batch_data = train_data[batch:batch+batch_size]\\n            batch_labels = train_labels[batch:batch+batch_size]\\n            \\n            # Compute the loss and gradients\\n            loss, grads = self.compute_loss_and_grads(batch_data, batch_labels)\\n            \\n            # Update the model parameters\\n            self.optimizer.update_params(learning_rate, grads)\\n        \\n        # Evaluate the model on the validation set\\n        val_loss = self.evaluate(val_data, val_labels)\\n        print(f\\'Epoch {epoch}: Train loss={loss:.4f}, Val loss={val_loss:.4f}\\')\\n    \\n    return self\",\\n  \"comment\": \"# Compute the loss and gradients\",\\n  \"explanation\": \"The comment is incorrect because it does not accurately describe what the code is doing. The code is not only computing the loss and gradients, but also updating the model parameters using the optimizer.\",\\n  \"correct\": false\\n}'}}\n"
     ]
    }
   ],
   "source": [
    "with Path(\"test_batch\").open(\"rb\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f5c98-2363-4092-8eee-608836ec612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "reqs, ids = prepare_batch(batch_size)\n",
    "message_batch = create_batch_and_wait(reqs)\n",
    "_ = retrieve_and_save_batch(message_batch, \"role_domain_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec481af-2e68-4248-a872-4590e663aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"role_domain_1000_ids\").open(\"wb\") as f:\n",
    "    pickle.dump(ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62175c-2d13-4b7e-8fea-8e40adfcacdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
